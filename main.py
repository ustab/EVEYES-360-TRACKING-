import streamlit as st
import cv2
import mediapipe as mp
import time

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="EVEYES 360 Master Control", layout="wide")

st.title("ğŸ¥ EVEYES 360 - AI Hospital-Home Tracking")
st.sidebar.header("ğŸ“Š Sistem Durumu")
st.sidebar.success("Sistem: AKTÄ°F")

# --- MEDIAPIPE HAZIRLIK ---
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

# --- DASHBOARD PANELÄ° ---
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ“· CanlÄ± AI Analiz AkÄ±ÅŸÄ±")
    frame_placeholder = st.empty() # GÃ¶rÃ¼ntÃ¼ buraya basÄ±lacak

with col2:
    st.subheader("ğŸš¨ AnlÄ±k Bildirimler")
    alert_placeholder = st.empty()
    st.subheader("ğŸŒ¡ï¸ Vital Veriler (SimÃ¼le)")
    temp_chart = st.line_chart([36.5, 36.6, 36.8, 37.1])

# --- CANLI GÃ–RÃœNTÃœ Ä°ÅLEME DÃ–NGÃœSÃœ ---
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # MediaPipe Ä°ÅŸleme
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb_frame)

    # Ä°skelet Ã‡izimi
    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        # Basit Bir DÃ¼ÅŸme Analizi GÃ¶stergesi
        nose_y = results.pose_landmarks.landmark[0].y
        if nose_y > 0.7: # EÅŸik deÄŸer
            alert_placeholder.error("UYARI: DÃ¼ÅŸme AlgÄ±landÄ±! (Oda 204)")
        else:
            alert_placeholder.info("Durum: Hasta Stabil")

    # Streamlit'e GÃ¶rÃ¼ntÃ¼yÃ¼ Bas
    frame_placeholder.image(frame, channels="BGR", use_column_width=True)
    
    time.sleep(0.01) # CPU'yu yormamak iÃ§in

cap.release()
import cv2
import face_recognition
import numpy as np

# 1. ADIM: Bilinen YÃ¼zlerin Sisteme Kaydedilmesi (Veri TabanÄ± Ã–n HazÄ±rlÄ±ÄŸÄ±)
# Burada Ã¶rnek olarak bir doktorun fotoÄŸrafÄ±nÄ± yÃ¼klÃ¼yoruz.
# 'doktor_foto.jpg' dosyasÄ±nÄ±n projenizle aynÄ± klasÃ¶rde olduÄŸundan emin olun.

try:
   doktor_image = face_recognition.load_image_file("doktor_foto.jpg")
   doktor_face_encoding = face_recognition.face_encodings(doktor_image)[0]
except IndexError:
    #print("HATA: FotoÄŸrafta yÃ¼z bulunamadÄ± veya dosya yok.")

# TanÄ±nan yÃ¼zlerin listesi ve isimleri
known_face_encodings = [doktor_face_encoding]
known_face_names = ["Dr. Ahmet Yilmaz"]

# 2. ADIM: Kamera AkÄ±ÅŸÄ±nÄ± BaÅŸlatma
video_capture = cv2.VideoCapture(0) # '0' varsayÄ±lan kameradÄ±r.

print("EVEYES 360 Sistemi BaÅŸlatÄ±ldÄ±. GÃ¶zlem YapÄ±lÄ±yor...")

while True:
    # Kameradan tek bir kare (frame) yakala
    ret, frame = video_capture.read()
    
    # Ä°ÅŸleme hÄ±zÄ±nÄ± artÄ±rmak iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ 1/4 oranÄ±nda kÃ¼Ã§Ã¼ltelim
    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
    
    # BGR (OpenCV formatÄ±) gÃ¶rÃ¼ntÃ¼yÃ¼ RGB (face_recognition formatÄ±) formatÄ±na Ã§evir
    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

    # Kare iÃ§indeki tÃ¼m yÃ¼zleri ve kodlamalarÄ±nÄ± bul
    face_locations = face_recognition.face_locations(rgb_small_frame)
    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

    for face_encoding in face_encodings:
        # Mevcut yÃ¼zÃ¼n 'bilinen yÃ¼zler' ile eÅŸleÅŸip eÅŸleÅŸmediÄŸine bak
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
        name = "Bilinmeyen Hasta" # VarsayÄ±lan deÄŸer

        # En yakÄ±n eÅŸleÅŸmeyi bul
        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
        best_match_index = np.argmin(face_distances)
        if matches[best_match_index]:
            name = known_face_names[best_match_index]

        # Sonucu ekranda gÃ¶ster (Burada analiz sonuÃ§larÄ± Master Kontrol'e gidecek)
        print(f"Tespit Edilen KiÅŸi: {name}")

    # GÃ¶rÃ¼ntÃ¼ penceresini gÃ¶ster (GeliÅŸtirme aÅŸamasÄ± iÃ§in)
    cv2.imshow('EVEYES 360 - Kamera Akisi', frame)

    # 'q' tuÅŸuna basÄ±lÄ±rsa dÃ¶ngÃ¼den Ã§Ä±k
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Sistemi kapat
video_capture.release()
cv2.destroyAllWindows()
import speech_recognition as sr
from deep_translator import GoogleTranslator
from gtts import gTTS
import os

def translate_and_speak(text, target_lang='tr'):
    """Metni hedef dile Ã§evirir ve seslendirir."""
    # 1. Ã‡eviri Ä°ÅŸlemi
    translated = GoogleTranslator(source='auto', target=target_lang).translate(text)
    print(f"Orijinal: {text}")
    print(f"Ã‡eviri ({target_lang}): {translated}")
    
    # 2. Seslendirme (Opsiyonel - AI Agent Cevap Veriyor)
    # tts = gTTS(text=translated, lang=target_lang)
    # tts.save("response.mp3")
    # os.system("start response.mp3") # Windows iÃ§in Ã§alma komutu
    
    return translated

def listen_and_translate():
    recognizer = sr.Recognizer()
    
    with sr.Microphone() as source:
        print("\nEVEYES 360 Dinliyor... (LÃ¼tfen konuÅŸun)")
        # Arka plan gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ ayarla
        recognizer.adjust_for_ambient_noise(source, duration=1)
        audio = recognizer.listen(source)

    try:
        # Sesi Ã¶nce orijinal dilinde tanÄ± (Otomatik algÄ±lama iÃ§in baÅŸlangÄ±Ã§ta Ä°ngilizce/Global seÃ§ilebilir)
        original_text = recognizer.recognize_google(audio, language="en-US")
        
        # TanÄ±nan metni TÃ¼rkÃ§e'ye (Doktorun dili) Ã§evir
        translate_and_speak(original_text, target_lang='tr')
        
    except sr.UnknownValueError:
        print("EVEYES Sesi AnlayamadÄ±.")
    except sr.RequestError:
        print("Servis HatasÄ±: Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")

# Test iÃ§in Ã§alÄ±ÅŸtÄ±ralÄ±m
if __name__ == "__main__":
    listen_and_translate()

    import cv2
import mediapipe as mp
import math

# MediaPipe Pose (Poz) modÃ¼lÃ¼nÃ¼ hazÄ±rla
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)

def calculate_angle(a, b, c):
    """ÃœÃ§ nokta arasÄ±ndaki aÃ§Ä±yÄ± hesaplar (Ã–rn: Diz veya Dirsek aÃ§Ä±sÄ±)"""
    a = [a.x, a.y]
    b = [b.x, b.y]
    c = [c.x, c.y]
    radians = math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0])
    angle = abs(radians*180.0/math.pi)
    if angle > 180.0:
        angle = 360-angle
    return angle

# Kamera akÄ±ÅŸÄ±nÄ± baÅŸlat (AdÄ±m 1'deki video_capture'Ä± kullanabiliriz)
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # GÃ¶rÃ¼ntÃ¼yÃ¼ RGB'ye Ã§evir (MediaPipe RGB bekler)
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image)

    # GÃ¶rÃ¼ntÃ¼yÃ¼ tekrar BGR'ye Ã§evir (Ekranda gÃ¶stermek iÃ§in)
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    if results.pose_landmarks:
        # Ä°skelet Ã§izimini yap
        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Ã–rnek Analiz: Omuz ve KalÃ§a noktalarÄ±nÄ± al
        landmarks = results.pose_landmarks.landmark
        
        # 1. DÃœÅME TESPÄ°TÄ° (Basit MantÄ±k: BaÅŸ noktasÄ± kalÃ§a noktasÄ±nÄ±n Ã§ok altÄ±na inerse)
        nose_y = landmarks[mp_pose.PoseLandmark.NOSE].y
        hip_y = landmarks[mp_pose.PoseLandmark.HIP_LEFT].y
        
        if nose_y > hip_y + 0.2: # KiÅŸi yatay pozisyona yakÄ±nsa
            cv2.putText(image, "UYARI: DUSME TESPITI!", (50, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
            print("Kritik Durum: Hasta yere dÃ¼ÅŸmÃ¼ÅŸ olabilir!")

        # 2. SALDIRI / KAVGA TESPÄ°TÄ° (HÄ±zlÄ± kol hareketleri veya elin omuz hizasÄ±ndan yukarÄ±da olmasÄ±)
        wrist_y = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y
        shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y

        if wrist_y < shoulder_y: # El omuzdan yukarÄ±daysa (SaldÄ±rÄ± veya yardÄ±m isteme pozu)
            cv2.putText(image, "AGRESIF HAREKET / YARDIM CAGRISI", (50, 100), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    cv2.imshow('EVEYES 360 - Postur ve Hareket Analizi', image)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

import time
import random

class VitalMonitor:
    def __init__(self):
        # Normal deÄŸer aralÄ±klarÄ± (EÅŸik deÄŸerler)
        self.thresholds = {
            "temp": {"min": 36.0, "max": 38.0},
            "heart_rate": {"min": 60, "max": 100},
            "spO2": {"min": 95, "max": 100}
        }

    def read_from_sensors(self):
        """
        GerÃ§ek senaryoda burada seri porttan veya IP Ã¼zerinden 
        termal kamera/radar verisi okunur.
        Åimdilik sistemi test etmek iÃ§in simÃ¼lasyon verisi Ã¼retiyoruz.
        """
        # SensÃ¶rden gelen ham veri simÃ¼lasyonu
        current_data = {
            "temp": round(random.uniform(36.2, 39.5), 1),
            "heart_rate": random.randint(55, 110),
            "spO2": random.randint(90, 100)
        }
        return current_data

    def analyze_vitals(self, data):
        """Verileri analiz eder ve kritik bir durum varsa alarm Ã¼retir."""
        alerts = []
        
        # AteÅŸ KontrolÃ¼
        if data["temp"] > self.thresholds["temp"]["max"]:
            alerts.append(f"YÃœKSEK ATEÅ TESPÄ°TÄ°: {data['temp']}Â°C")
        
        # NabÄ±z KontrolÃ¼
        if data["heart_rate"] > self.thresholds["heart_rate"]["max"]:
            alerts.append(f"TAÅÄ°KARDÄ° RÄ°SKÄ°: {data['heart_rate']} BPM")
        elif data["heart_rate"] < self.thresholds["heart_rate"]["min"]:
            alerts.append(f"BRADÄ°KARDÄ° RÄ°SKÄ°: {data['heart_rate']} BPM")

        # Oksijen KontrolÃ¼
        if data["spO2"] < self.thresholds["spO2"]["min"]:
            alerts.append(f"DÃœÅÃœK OKSÄ°JEN (SpO2): %{data['spO2']}")

        return alerts

# --- ANA DÃ–NGÃœYE ENTEGRASYON TESTÄ° ---
monitor = VitalMonitor()

print("EVEYES 360 Vital Takip ModÃ¼lÃ¼ Aktif...")

try:
    while True:
        # 1. Veriyi Oku
        vitals = monitor.read_from_sensors()
        
        # 2. Analiz Et
        critical_alerts = monitor.analyze_vitals(vitals)
        
        # 3. Master Kontrol Paneline YazdÄ±r
        print(f"\r[TAKÄ°P] AteÅŸ: {vitals['temp']}Â°C | NabÄ±z: {vitals['heart_rate']} | SpO2: %{vitals['spO2']}", end="")
        
        if critical_alerts:
            print("\n" + "!"*30)
            for alert in critical_alerts:
                print(f"[KRÄ°TÄ°K UYARI]: {alert}")
            print("!"*30)
            # Burada Beyaz Kod veya Mavi Kod tetiklenebilir
        
        time.sleep(2) # 2 saniyede bir gÃ¼ncelle (Hastane standardÄ±)

except KeyboardInterrupt:
    print("\nVital Takip Durduruldu.")

    import json
from datetime import datetime

class ReportManager:
    def __init__(self, filename="hastane_log.json"):
        self.filename = filename
        self.logs = []

    def log_event(self, patient_name, event_type, details, severity="Normal"):
        """Her olayÄ± zaman damgasÄ±yla kaydeder."""
        entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "patient": patient_name,
            "type": event_type, # Vital, Hareket, TercÃ¼me, GÃ¼venlik
            "details": details,
            "severity": severity # Normal, Uyari, Kritik
        }
        self.logs.append(entry)
        self.save_to_file()

    def save_to_file(self):
        """Verileri kalÄ±cÄ± olarak dosyaya yazar."""
        with open(self.filename, 'w', encoding='utf-8') as f:
            json.dump(self.logs, f, ensure_ascii=False, indent=4)

    def generate_doctor_report(self, patient_name):
        """Doktor iÃ§in gÃ¼n sonu veya anlÄ±k Ã¶zet raporu oluÅŸturur."""
        patient_logs = [log for log in self.logs if log["patient"] == patient_name]
        
        print(f"\n--- DR. RAPORU: {patient_name} ---")
        print(f"Rapor Tarihi: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
        
        # Kritik olaylarÄ± filtrele
        criticals = [l for l in patient_logs if l["severity"] == "Kritik"]
        
        if criticals:
            print(f"\n[!] DÄ°KKAT: Son 24 saatte {len(criticals)} kritik olay saptandÄ±.")
            for c in criticals:
                print(f"- {c['timestamp']}: {c['details']}")
        else:
            print("\n[+] Hasta stabil. Kritik anomali saptanmadÄ±.")
        
        # Hareket ve PostÃ¼r Ã–zeti
        movements = [l for l in patient_logs if l["type"] == "Hareket"]
        if movements:
            print(f"- Hareket Analizi: {len(movements)} adet postÃ¼r deÄŸiÅŸikliÄŸi kaydedildi.")

# --- SÄ°STEM ENTEGRASYON TESTÄ° ---
report_system = ReportManager()

# Ã–RNEK SENARYO: Sistem Ã§alÄ±ÅŸÄ±rken verileri kaydeder
# 1. AdÄ±m: YÃ¼z TanÄ±ndÄ±
patient = "Ali Veli"

# 2. AdÄ±m: Vital Ã–lÃ§Ã¼ldÃ¼ (Kritik bir durum oluÅŸtu)
report_system.log_event(patient, "Vital", "NabÄ±z: 115 (TaÅŸikardi SaptandÄ±)", "Kritik")

# 3. AdÄ±m: PostÃ¼r Analizi
report_system.log_event(patient, "Hareket", "Yataktan kalkÄ±ÅŸ denemesi - Dengeli", "Normal")

# 4. AdÄ±m: TercÃ¼me YapÄ±ldÄ±
report_system.log_event(patient, "TercÃ¼me", "Hasta 'GÃ¶ÄŸsÃ¼mde baskÄ± var' dedi (RusÃ§a -> TÃ¼rkÃ§e)", "Uyari")

# 5. AdÄ±m: Doktor Raporu Ä°stendi
report_system.generate_doctor_report("Ali Veli")


import threading
import time

class EveyesSecuritySystem:
    def __init__(self):
        self.emergency_mode = False
        self.lock = threading.Lock()

    def camera_security_monitor(self):
        """Kamera verisinden kavga/saldÄ±rÄ± analizi yapar (3. AdÄ±m Entegrasyonu)"""
        while not self.emergency_mode:
            # Burada AI modelinden gelen 'saldÄ±rÄ±_olasiligi' verisi iÅŸlenir
            # Ã–rnek simÃ¼lasyon:
            aggression_score = random.randint(0, 100)
            if aggression_score > 90:
                self.trigger_alarm("GÃœVENLÄ°K: Fiziksel SaldÄ±rÄ±/Kavga SaptandÄ±!", "BEYAZ KOD")
            time.sleep(1)

    def audio_security_monitor(self):
        """Ses verisinden baÄŸÄ±rma/cam kÄ±rÄ±lmasÄ± analizi yapar (2. AdÄ±m Entegrasyonu)"""
        while not self.emergency_mode:
            # Burada 'imdat', 'help' veya yÃ¼ksek desibel analizi yapÄ±lÄ±r
            # Ã–rnek simÃ¼lasyon:
            noise_level = random.randint(30, 110)
            if noise_level > 100:
                self.trigger_alarm("SES: YÃ¼ksek Desibel / YardÄ±m Ã‡Ä±ÄŸlÄ±ÄŸÄ± SaptandÄ±!", "BEYAZ KOD")
            time.sleep(1)

    def fire_thermal_monitor(self):
        """Termal kameradan yangÄ±n/duman analizi yapar (4. AdÄ±m Entegrasyonu)"""
        while not self.emergency_mode:
            # Termal Ä±sÄ± eÅŸiÄŸi kontrolÃ¼
            temp_spot = random.uniform(20.0, 100.0)
            if temp_spot > 80.0:
                self.trigger_alarm("YANGIN: Kritik IsÄ± ArtÄ±ÅŸÄ± SaptandÄ±!", "KIRMIZI KOD")
            time.sleep(1)

    def trigger_alarm(self, reason, code):
        """TÃ¼m sistemi kriz moduna sokar ve Master Kontrol'e bildiri gÃ¶nderir."""
        with self.lock:
            if not self.emergency_mode:
                self.emergency_mode = True
                print(f"\n\n{'!'*50}")
                print(f"!!! ACÄ°L DURUM AKTÄ°VE EDÄ°LDÄ° !!!")
                print(f"NEDEN: {reason}")
                print(f"SÄ°STEM KODU: {code}")
                print(f"AKSÄ°YON: GÃ¼venlik birimleri yÃ¶nlendirildi. Tahliye rotalarÄ± aÃ§Ä±ldÄ±.")
                print(f"{'!'*50}\n")
                
                # Burada donanÄ±msal tetiklemeler yapÄ±labilir:
                # smart_locks.unlock_all()
                # sirens.start()

# --- SÄ°STEMÄ° EÅ ZAMANLI Ã‡ALIÅTIRALIM ---
security = EveyesSecuritySystem()

# Her sensÃ¶r analizini ayrÄ± bir 'iÅŸ parÃ§acÄ±ÄŸÄ±' (thread) olarak baÅŸlatÄ±yoruz
t1 = threading.Thread(target=security.camera_security_monitor)
t2 = threading.Thread(target=security.audio_security_monitor)
t3 = threading.Thread(target=security.fire_thermal_monitor)

print("EVEYES 360 Master Kontrol: GÃ¼venlik KatmanÄ± BaÅŸlatÄ±ldÄ±...")

t1.start()
t2.start()
t3.start()

# Ana programÄ±n kapanmamasÄ± iÃ§in bekletiyoruz
t1.join()

from fastapi import FastAPI
import threading
import random

app = FastAPI(title="EVEYES 360 Master Control API")

# Global sistem durumu (ModÃ¼llerden gelen veriler burada toplanacak)
system_status = {
    "security": {"status": "GÃœVENLÄ°", "last_alert": "Yok", "code": "YEÅÄ°L"},
    "patients": [
        {"id": 1, "name": "Ali Veli", "temp": 36.5, "hr": 75, "status": "Stabil", "lang": "TR"},
        {"id": 2, "name": "Hans MÃ¼ller", "temp": 38.2, "hr": 95, "status": "GÃ¶zlem AltÄ±nda", "lang": "DE"}
    ],
    "environment": {"fire_risk": "DÃ¼ÅŸÃ¼k", "noise_level": "Normal"}
}

# --- ENDPOINT'LER (ArayÃ¼zÃ¼n veri Ã§ekeceÄŸi kapÄ±lar) ---

@app.get("/")
def read_root():
    return {"message": "EVEYES 360 Master Control Merkezi Aktif"}

@app.get("/dashboard")
def get_dashboard_data():
    """TÃ¼m hastane durumunu tek seferde dÃ¶ner."""
    return system_status

@app.get("/patient/{patient_id}")
def get_patient_detail(patient_id: int):
    """Belirli bir hastanÄ±n AI-Agent analizlerini getirir."""
    patient = next((p for p in system_status["patients"] if p["id"] == patient_id), None)
    if patient:
        return {
            "patient_info": patient,
            "ai_insights": [
                "PostÃ¼r Analizi: Normal",
                "TercÃ¼me Ä°htiyacÄ±: DÃ¼ÅŸÃ¼k",
                "Tahmini Taburcu: 2 GÃ¼n"
            ]
        }
    return {"error": "Hasta bulunamadÄ±"}

@app.post("/trigger-alarm")
def manual_alarm(code: str, reason: str):
    """GÃ¼venlik amirinin manuel alarm baÅŸlatmasÄ±nÄ± saÄŸlar."""
    system_status["security"]["status"] = "ACÄ°L DURUM"
    system_status["security"]["code"] = code
    system_status["security"]["last_alert"] = reason
    return {"status": "Alarm Aktive Edildi", "code": code}

# --- SÄ°STEMÄ° BAÅLATMA ---
if __name__ == "__main__":
    import uvicorn
    # Bu komutla API sunucusu 8000 portunda baÅŸlar
    uvicorn.run(app, host="0.0.0.0", port=8000)


    import cv2
import threading
from queue import Queue

class SmartCameraStream:
    def __init__(self, rtsp_url):
        # NVIDIA Jetson iÃ§in donanÄ±m hÄ±zlandÄ±rmalÄ± GStreamer pipeline'Ä±
        # Bu satÄ±r, CPU'yu yormadan GPU Ã¼zerinden gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§Ã¶zer
        self.pipeline = (
            f"rtspsrc location={rtsp_url} latency=0 ! "
            "rtph264depay ! h264parse ! nvv4l2decoder ! "
            "nvvidconv ! video/x-raw, format=BGRx ! videoconvert ! appsink"
        )
        self.cap = cv2.VideoCapture(self.pipeline, cv2.CAP_GSTREAMER)
        self.q = Queue()
        self.stopped = False

    def _reader(self):
        """Kameradan gelen kareleri sÃ¼rekli oku ve kuyruÄŸa at (Frame Buffer)"""
        while not self.stopped:
            ret, frame = self.cap.read()
            if not ret:
                break
            if not self.q.empty():
                try:
                    self.q.get_nowait() # Eski kareyi at (GerÃ§ek zamanlÄ±lÄ±k iÃ§in)
                except:
                    pass
            self.q.put(frame)

    def get_frame(self):
        return self.q.get()

    def stop(self):
        self.stopped = True
        self.cap.release()

# --- ENTEGRASYON ---
# Ã–rn: Acil Servis KamerasÄ±
camera_1 = SmartCameraStream("rtsp://admin:password@192.168.1.50:554/stream")
t = threading.Thread(target=camera_1._reader)
t.start()

while True:
    frame = camera_1.get_frame()
    
    # Burada daha Ã¶nce yazdÄ±ÄŸÄ±mÄ±z AI modÃ¼llerini Ã§aÄŸÄ±rÄ±yoruz:
    # 1. YÃ¼zÃ¼ bul -> recognize_faces(frame)
    # 2. Ä°skeleti Ã§Ä±kar -> detect_pose(frame)
    # 3. Åiddet var mÄ±? -> analyze_aggression(frame)
    
    cv2.imshow("EVEYES 360 Live - Emergency Ward", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

camera_1.stop()
import multiprocessing as mp
import time

def thermal_sensor_worker(data_queue):
    """Termal sensÃ¶rden baÄŸÄ±msÄ±z bir Ã§ekirdekte veri okur."""
    while True:
        # GerÃ§ek sensÃ¶r okuma kodu burada olacak
        simulated_temp = 36.6 + (time.time() % 2) 
        data_queue.put({"type": "thermal", "val": simulated_temp})
        time.sleep(0.125) # 8 Hz

def camera_ai_worker(data_queue):
    """NVIDIA TensorRT kullanarak GPU Ã¼zerinden gÃ¶rÃ¼ntÃ¼ iÅŸler."""
    while True:
        # AI Analiz sonuÃ§larÄ±
        # Ã–rn: detect_fall() -> True
        data_queue.put({"type": "vision", "alert": "Fall Detected"})
        time.sleep(0.033) # 30 FPS

if __name__ == "__main__":
    shared_queue = mp.Queue()
    
    # SÃ¼reÃ§leri baÅŸlat
    p1 = mp.Process(target=thermal_sensor_worker, args=(shared_queue,))
    p2 = mp.Process(target=camera_ai_worker, args=(shared_queue,))
    
    p1.start()
    p2.start()

    # MASTER ANALÄ°ZÃ–R: Gelen verileri birleÅŸtirir (Data Fusion)
    while True:
        if not shared_queue.empty():
            data = shared_queue.get()
            if data['type'] == 'thermal' and data['val'] > 39.0:
                print(f"KRÄ°TÄ°K: HastanÄ±n ateÅŸi yÃ¼kseldi! ({data['val']}Â°C)")
            if data['type'] == 'vision' and data['alert'] == 'Fall Detected':
                print("ACÄ°L: DÃ¼ÅŸme algÄ±landÄ±! Kameralar odaya odaklanÄ±yor.")


# FarklÄ± sensÃ¶rlerden gelen veriyi 'Timestamp' (Zaman DamgasÄ±) ile eÅŸleÅŸtirme
def sync_sensor_data(vision_data, vital_data):
    # EÄŸer vizyon dÃ¼ÅŸme diyorsa VE nabÄ±z aniden yÃ¼kselmiÅŸse (STRESS DETECTED)
    if vision_data['action'] == "fallen" and vital_data['heart_rate'] > 110:
        return "CRITICAL ALERT: FALL + HIGH DISTRESS"
    return "MONITORING"
# Modeli Jetson Ã¼zerinde GPU ile Ã§alÄ±ÅŸtÄ±rmak iÃ§in Ã¶rnek motor baÅŸlatma
import tensorrt as trt

def load_engine(engine_file_path):
    # Bu fonksiyon, AI modelini donanÄ±mÄ±n mimarisine gÃ¶re optimize eder
    with open(engine_file_path, "rb") as f, trt.Runtime(TRT_LOGGER) as runtime:
        return runtime.deserialize_cuda_engine(f.read())

# AI iÅŸlemlerini 'Asenkron' (Async) yaparak kameranÄ±n donmasÄ±nÄ± engelliyoruz


